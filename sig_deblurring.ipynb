{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2bac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "d = 256\n",
    "\n",
    "s1 = pi # width of the gaussian\n",
    "\n",
    "t = arange(- d / 2, d / 2)\n",
    "h = (1 - t ** 2 / s1 ** 2) * exp(- (t ** 2) / (2 * s1 ** 2))\n",
    "h = h - h.mean()\n",
    "\n",
    "h_tf = fft.fft(fft.fftshift(h))\n",
    "opA = lambda u : real(fft.ifft(fft.fft(u) * h_tf))\n",
    "\n",
    "s = 16 # number of nonzero elements of xsharp\n",
    "\n",
    "def training_set(n, var):\n",
    "    x_train = zeros((d, n))\n",
    "    eps_train = zeros((d, n))        \n",
    "    y_train = zeros((d, n))\n",
    "    for i in range(n):\n",
    "        nonzero_indices = random.choice(d, s, replace=False)\n",
    "        nonzero_values = random.uniform(-1, 1, s)\n",
    "        x0 = zeros(d)\n",
    "        x0[nonzero_indices] = nonzero_values\n",
    "        x_train[:, i] = x0 / norm(x0, ord=2)\n",
    "        \n",
    "        eps_train[:, i] = random.normal(0, var, d)\n",
    "\n",
    "        y_train[:, i] =  opA(x_train[:, i]) + eps_train[:, i]\n",
    "\n",
    "    return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute here D_||.||_1(x, y). Inputs vectors/matrices, outputs number\n",
    "def breg_dist_l1(x, y): \n",
    "    norm_x = norm(x, ord=1)\n",
    "    dot_prod = np.dot(np.sign(y), x)\n",
    "    return norm_x - dot_prod\n",
    "\n",
    "beta = abs(fft.fft(h)).max() ** 2\n",
    "gamma = 1.3 / beta\n",
    "\n",
    "# soft thresholding function here:\n",
    "def st(x, Lambda):\n",
    "    y = x - x / np.maximum(np.abs(x) / (Lambda * gamma), 1) \n",
    "    return y \n",
    "\n",
    "def fista(y, lam, warm_start_w=None):\n",
    "    w = warm_start_w.copy() if warm_start_w is not None else np.zeros(len(y))\n",
    "    z = zeros(len(y))\n",
    "    nor1 = np.inf\n",
    "    it = 0\n",
    "    t_new = 1\n",
    "    while nor1 >= 1e-6:\n",
    "        t_old = t_new\n",
    "        t_new = (1 + np.sqrt(1 + 4 * t_old ** 2)) / 2\n",
    "        w_old = w.copy()\n",
    "        z -= gamma * opA(opA(z) - y)\n",
    "        w = st(z, lam)\n",
    "        z = w + (t_old - 1.) / t_new * (w - w_old)\n",
    "        nor1 = norm(w - w_old, ord=1)\n",
    "        it += 1\n",
    "    return w, it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc459bd-2df0-44fd-a3bd-f4c0a53b733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training functions\n",
    "def train_l1(x_tr, y_tr, la):\n",
    "    n_tr = x_tr.shape[1]\n",
    "    distances = []\n",
    "    for i in range(n_tr):\n",
    "        f_lasso = fista(y_tr[:, i], la)[0]\n",
    "        err = breg_dist_l1(x_tr[:, i], f_lasso)\n",
    "        distances.append(err)\n",
    "    return np.mean(distances)\n",
    "\n",
    "def get_lambda(x_tr, y_tr, lamb): \n",
    "    num_cores = -1  #(-1 uses all available cores) \n",
    "    l1_err = Parallel(n_jobs=num_cores)(delayed(train_l1)(x_tr, y_tr, la) for la in lamb)\n",
    "    l1_err = np.array(l1_err)\n",
    "    min_index = np.argmin(l1_err)\n",
    "    return lamb[min_index], l1_err.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819496ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debl1 plot\n",
    "\n",
    "lamb = logspace(-2, 0, num=50)\n",
    "std = 0.25\n",
    "N_big = 1000\n",
    "x_big, y_big = training_set(N_big, std)\n",
    "\n",
    "N_vec = arange(5, 51, 5)\n",
    "n_it = 30  # The perfect number of iterations is 30\n",
    "\n",
    "L_at_lhatn = zeros((len(N_vec), n_it))\n",
    "lamb_hatn = zeros((len(N_vec), n_it))\n",
    "\n",
    "for i in range(len(N_vec)):\n",
    "    print('n=', N_vec[i])          \n",
    "    for j in range(n_it):\n",
    "        xsmall, ysmall = training_set(N_vec[i], std)\n",
    "        lamb_hatn[i, j] = get_lambda(xsmall, ysmall, lamb)[0]\n",
    "        L_at_lhatn[i, j] = train_l1(x_big, y_big, lamb_hatn[i, j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d182d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanlasso = mean(L_at_lhatn, axis=1)\n",
    "lowerlasso = quantile(L_at_lhatn, 0.05, axis=1)\n",
    "upperlasso = quantile(L_at_lhatn, 0.95, axis=1)\n",
    "\n",
    "# Figures\n",
    "\n",
    "plt.close('all')\n",
    "fig, ax1 = plt.subplots(figsize=(20, 5), dpi=300)\n",
    "ax1.plot(N_vec, meanlasso, '-')\n",
    "ax1.scatter(N_vec, meanlasso, color='red', s=50)\n",
    "ax1.fill_between(N_vec, lowerlasso, upperlasso, alpha=0.2)\n",
    "ax1.set_ylabel(r'$L(X_{\\widehat{\\lambda}(n)})$', fontsize=25)\n",
    "ax1.set_xlabel(r'$n$', fontsize=25)\n",
    "ax1.set_xscale('log')\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.savefig(\"./debl1_tau=0.25.pdf\", bbox_inches='tight')  # This shud go before show\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2313e-5bdd-4593-9657-37dd23b0c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#debl2 plot\n",
    "lamb1 = np.logspace(-2, 1, num=50)\n",
    "lamb2 = np.logspace(-2, 1, num=10)\n",
    "tau = np.logspace(-1, 0, num=30)\n",
    "\n",
    "n_it = 30\n",
    "bign = 500\n",
    "smalln = 5\n",
    "\n",
    "bign = 500\n",
    "smalln = 5\n",
    "n_it = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c003d6-20ea-4216-8887-0a4fe0f17695",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb_star = np.zeros(len(tau))\n",
    "Lstar = np.zeros(len(tau))\n",
    "\n",
    "lamb_hat = np.zeros((len(tau), n_it))\n",
    "Lhat = np.zeros((len(tau), n_it))\n",
    "\n",
    "for i in range(len(tau)):\n",
    "    print('tau=', tau[i])\n",
    "    x_bign, y_bign = training_set(bign, tau[i])\n",
    "    lamb_star[i], Lstar[i] = get_lambda(x_bign, y_bign, lamb1)\n",
    "    for j in range(n_it):\n",
    "        x_smalln, y_smalln = training_set(smalln, tau[i])\n",
    "        lamb_hat[i, j] = get_lambda(x_smalln, y_smalln, lamb2)[0] \n",
    "        Lhat[i, j] = train_l1(x_bign, y_bign, lamb_hat[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc12655-1144-4d52-93f5-ec4a09698cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "meandbl = np.mean(Lhat, axis=1) \n",
    "lowerdbl = np.quantile(Lhat, 0.05, axis=1) \n",
    "upperdbl = np.quantile(Lhat, 0.95, axis=1) \n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fig, ax1 = plt.subplots(1, figsize=(20, 5), dpi=300)\n",
    "\n",
    "ax1.plot(tau, meandbl, linestyle='-', label=r'$L(X_{\\widehat{\\lambda}_\\Lambda(\\tau)})$')\n",
    "ax1.fill_between(tau, lowerdbl, upperdbl, alpha=0.2)\n",
    "ax1.plot(tau, Lstar, linestyle='-', label=r'$L(X_{\\widehat{\\lambda}_\\Lambda(\\tau)})$')\n",
    "ax1.legend(fontsize=20)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "ax1.tick_params(axis='both', which='minor', labelsize=20)\n",
    "\n",
    "fig.supxlabel(r\"$\\tau$\", fontsize=25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./debl2.pdf\", bbox_inches='tight')\n",
    "plt.show(block='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312719f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test FISTA here with la^, selected with 100 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = training_set(100, var = 0.1)\n",
    "lamb = logspace(-2, 0, num=50)\n",
    "lambda_hat = get_lambda(x_train, y_train, lamb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0605474",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 5\n",
    "x_test, y_test = training_set(N_test, var=0.1)\n",
    "\n",
    "x = x_test[:, 0]\n",
    "y = y_test[:, 0]\n",
    "y_lasso = fista(y, lambda_hat)[0]\n",
    "\n",
    "fig, (ax_orig, ax_filtered, ax_rec) = plt.subplots(3, 1, sharex=True, figsize=(20, 8), dpi=300)\n",
    "ax_orig.stem(x)\n",
    "ax_orig.set_title('Original', fontsize=25)\n",
    "ax_orig.set_xlim(0, d - 1)\n",
    "ax_orig.tick_params(axis='y', labelsize=20)\n",
    "ax_filtered.stem(y)\n",
    "ax_filtered.set_title('Blurred, noisy', fontsize=25)\n",
    "ax_filtered.margins(0, 0.1)\n",
    "ax_filtered.tick_params(axis='y', labelsize=20)\n",
    "ax_rec.stem(y_lasso)\n",
    "ax_rec.set_title('Recovered', fontsize=25)\n",
    "ax_rec.margins(0, 0.1)\n",
    "ax_rec.tick_params(axis='y', labelsize=20)\n",
    "plt.subplots_adjust(hspace=0.5) \n",
    "plt.xticks(fontsize=20)\n",
    "plt.savefig(\"./debl3.pdf\", bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
